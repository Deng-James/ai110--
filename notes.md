# 筆記

## 授權聲明
* 文章取自[維基百科 圖靈測試](https://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95)
* 文章取自[維基百科 下棋AlphaGo](https://zh.m.wikipedia.org/zh-tw/AlphaGo)
* 本專案的程式碼來源自陳鍾誠老師的[專案](https://gitlab.com/ccc110/ai)
* 本專案的程式碼來源Medium [作者:Tzu-Chieh Tang](https://tzuchieh0931.medium.com/hc-metaheuristic-02-a071980b37e6)
* 本專案的程式碼來源Medium [作者:Tommy Huang](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f)
## 圖靈測試
圖靈測試（英語：Turing test）是英國電腦科學家圖靈於1950年提出的思想實驗，目的在測試機器能否表現出與人一樣的智慧型水準。測試時測試者通過電腦鍵盤輸入文字並通過螢幕輸出文字。

#### 歷史
```
機器能否思考這個問題歷史悠久，這是二元並存理念和唯物論思想之間的區別。笛卡爾在1637年《談談方法》中預言了圖靈測試。
笛卡爾指出，機器能夠與人類互動，但認為這樣的機器不能作出適當的反應，但是任何人都可以。因此，笛卡爾藉此區分機器與人類。笛卡爾沒有考慮到機器語言能力未來能夠被克服。
狄德羅對於圖靈測試的標準：
如果他們發現一隻鸚鵡可以回答一切問題，我會毫不猶豫宣布它存在智慧型。
——狄德羅，Pensées philosophiques, Texte établi par J. Assézat et M. Tourneux, Garnier, I (p. 127-155).
這並不意味著他同意這一點，但它已經是唯物主義者當時普遍的說法。

根據二元論者心態，心靈是非物理物質（最起碼具有非物理性），因此不能以純物理來解釋。根據唯物主義，頭腦可以用物理解釋，這讓那些人工智慧可能性產生。

1936年，哲學家阿爾弗雷德·艾耶爾思考心靈哲學問題：我們怎麼知道其他人曾有同樣的體驗。在《語言，真理與邏輯》中，艾爾建議有意識的人類及無意識的機器之間的區別。

1956年達特茅斯會議之前，英國研究者已經探索十幾年的機器人工智慧研究。比率俱樂部是一個非正式的英國控制論和電子產品研究團體，成員包括艾倫·圖靈。

1950年，圖靈發表了一篇劃時代的論文，文中預言了創造出具有真正智慧型的機器的可能性。[2]由於注意到「智慧型」這一概念難以確切定義，他提出了著名的圖靈測試：如果一台機器能夠與人類展開對話（通過電傳裝置）而不被辨別出其機器身分，那麼稱這台機器具有智慧型。這一簡化使得圖靈能夠令人信服地說明「思考的機器」是可能的。論文中還回答了對這一假說的各種常見質疑。[3]圖靈測試是人工智慧哲學方面首個嚴肅的提案。

2014年6月8日，首次有電腦通過圖靈測試，尤金·古斯特曼成功在雷丁大學（University of Reading）所舉辦的測試中騙過研究人員，令他們以為「它」是一個名為Eugene Goostman的13歲男孩[4]，但後來有文章指它其實並沒有真正通過測試[5]。
```

## 爬山演算法(Hill Climbing)
#### 簡介
爬山演算法(HC)是一種較為貪婪的超啟發式方法，像是模仿人類登山一樣一直往高處前進(對機器來說就是越好的解)，個人認為爬山演算法還無啟發的感覺只停留在隨機的概念上，但對於想初探該領域的人，爬山演算法是個最容易入門的方法。在文章最後也附上自己寫的程式碼。

#### 概念
爬山演算法顧名思義，是一種模擬爬山行為的一種演算法，如果更新的解優於當前解則更新，反之則否。
#### 程式流程
我們在執行超啟發式演算法時會給予程式一個終止條件，稱為迭代次數(Iteration)，在後續多粒子的演算法，稱為衡量次數(Evaluation)會更加恰當，但在這邊還是以迭代次數來進行說明。
而此類演算法大致的運行流程通常為以下四步，一開始進行隨機初始化(1)，接著會持續進行解的更新，不斷的進行TED(2–4)的步驟，直到設定的迭代次數才終止。

![image](https://user-images.githubusercontent.com/55796905/174220448-94e35daf-c16b-48f3-8788-73c434dfdb5e.png)  
![image](https://user-images.githubusercontent.com/55796905/174220484-ad5c6167-123c-4ea8-bb68-13b8b7a59561.png)
![image](https://user-images.githubusercontent.com/55796905/174220500-3ef81f43-d8d8-4082-9943-772393664f84.png)
![image](https://user-images.githubusercontent.com/55796905/174220517-ccc11dd2-8457-4663-b0b4-33f8544d7392.png)
![image](https://user-images.githubusercontent.com/55796905/174220530-294d7ec9-e413-454c-8f6e-3780a2612e95.png)
![image](https://user-images.githubusercontent.com/55796905/174220592-e57f944a-e175-4cd3-ae63-129f74856c6a.png)
![image](https://user-images.githubusercontent.com/55796905/174220622-6dddca98-6744-4c02-b891-3d793e643ffc.png)

## 下棋AlphaGo
AlphaGo（「Go」為日文「碁」字發音轉寫，是圍棋的西方名稱），直譯為阿爾法圍棋，亦被音譯為阿爾法狗[1][2]、阿法狗[3]、阿發狗[4][5]等，是於2014年開始由英國倫敦Google DeepMind開發的人工智慧圍棋軟體。2017年，關於AlphaGo的電影紀錄片《AlphaGo世紀對決》正式上映。
專業術語上來說，AlphaGo的做法是使用了蒙地卡羅樹搜尋與兩個深度神經網路相結合的方法，一個是以藉助估值網路（value network）來評估大量的選點，一個是藉助走棋網路（policy network）來選擇落子，並使用強化學習進一步改善它。在這種設計下，電腦可以結合樹狀圖的長遠推斷，又可像人類的大腦一樣自發學習進行直覺訓練，以提高下棋實力。

## 梯度下降法(gradient descent)
梯度下降法(gradient descent)是最佳化理論裡面的一個一階找最佳解的一種方法，主要是希望用梯度下降法找到函數(剛剛舉例的式子)的局部最小值，因為梯度的方向是走向局部最大的方向，所以在梯度下降法中是往梯度的反方向走。

紅色的點是每一次更新找到的解

紅色線是法線，藍色線是切線，法線和切線這兩條線是垂直的，但因為x軸和y軸scale不一樣，所以看不出來它是垂直的。
![image](https://miro.medium.com/max/1120/1*PyXvVaaz4OSA_J6VdXlAJw.gif)


